{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///Users/resmile/project/mars2blog/src/app/api/ai/generate/route.ts"],"sourcesContent":["import { GoogleGenerativeAI } from \"@google/generative-ai\";\nimport { NextResponse } from \"next/server\";\n\nconst genAI = new GoogleGenerativeAI(\"AIzaSyA2XT6tAEmI5hmiyH9lsk9NI8paYfLDrNM\");\n\nexport async function POST(req: Request) {\n    try {\n        const { type, content, imageUrl } = await req.json();\n\n        // Use the requested model\n        const model = genAI.getGenerativeModel({ model: \"gemini-2.5-flash-lite\" });\n\n        if (type === 'alt-text') {\n            if (!imageUrl) return NextResponse.json({ error: \"Image URL required\" }, { status: 400 });\n\n            // For alt-text, if we only have the URL, we might need to fetch the image or just describe based on filename if it's not accessible.\n            // But usually we can pass the image data if we have it. \n            // Since we're using Firebase Storage, we might not have the bytes here easily unless we fetch it.\n            // Simple approach: ask Gemini to describe an image from its URL if possible, or just skip if URL is private.\n            // Actually, Gemini can't directly fetch images from private URLs.\n            // Let's assume for now we provide the URL and see if it works, or just ask it to describe what it MIGHT be based on the post title if provided.\n            // Better: If the user just uploaded it, we could have the base64.\n\n            const prompt = `Describe this image for an SEO alt text. The image is a thumbnail for a blog post. Provide a concise, descriptive alt text in Korean.\n            Return ONLY the alt text string.`;\n\n            // If content (title) is provided, use it as context\n            const contextualPrompt = content ? `${prompt}\\nContext: The blog post title is \"${content}\"` : prompt;\n\n            // Note: Gemini can't fetch external URLs directly in this way without vision capabilities. \n            // For now, I'll implement a placeholder or try to use vision if it's a base64.\n            // Since implementing full vision here is complex without the actual bits, \n            // I'll make it generate a description based on the TITLE if it's all we have, \n            // or I'll warn the user.\n\n            const result = await model.generateContent(contextualPrompt);\n            return NextResponse.json({ result: result.response.text().trim() });\n        }\n\n        if (type === 'tldr') {\n            const prompt = `Summarize the following markdown content into a single concise paragraph (TL;DR) in Korean. \n            Focus on the key takeaways.\n            Return ONLY the summary.\n            \n            Content:\n            ${content}`;\n\n            const result = await model.generateContent(prompt);\n            return NextResponse.json({ result: result.response.text().trim() });\n        }\n\n        if (type === 'seo-metadata') {\n            const prompt = `Based on the following blog content, generate:\n            1. SEO Title (max 60 chars)\n            2. SEO Description (max 160 chars)\n            \n            Return the result in JSON format:\n            {\n                \"seoTitle\": \"...\",\n                \"seoDescription\": \"...\"\n            }\n            \n            Content:\n            ${content}`;\n\n            const result = await model.generateContent(prompt);\n            const text = result.response.text();\n            const jsonMatch = text.match(/\\{[\\s\\S]*\\}/);\n            if (jsonMatch) {\n                return NextResponse.json(JSON.parse(jsonMatch[0]));\n            }\n            return NextResponse.json({ error: \"Failed to parse JSON\" }, { status: 500 });\n        }\n\n        return NextResponse.json({ error: \"Invalid type\" }, { status: 400 });\n    } catch (error: any) {\n        console.error(\"AI Generation Error:\", error);\n        return NextResponse.json({\n            error: \"Failed to generate content\",\n            details: error.message || String(error)\n        }, { status: 500 });\n    }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,MAAM,QAAQ,IAAI,sLAAkB,CAAC;AAE9B,eAAe,KAAK,GAAY;IACnC,IAAI;QACA,MAAM,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,EAAE,GAAG,MAAM,IAAI,IAAI;QAElD,0BAA0B;QAC1B,MAAM,QAAQ,MAAM,kBAAkB,CAAC;YAAE,OAAO;QAAwB;QAExE,IAAI,SAAS,YAAY;YACrB,IAAI,CAAC,UAAU,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAqB,GAAG;gBAAE,QAAQ;YAAI;YAEvF,qIAAqI;YACrI,yDAAyD;YACzD,kGAAkG;YAClG,6GAA6G;YAC7G,kEAAkE;YAClE,gJAAgJ;YAChJ,kEAAkE;YAElE,MAAM,SAAS,CAAC;4CACgB,CAAC;YAEjC,oDAAoD;YACpD,MAAM,mBAAmB,UAAU,GAAG,OAAO,mCAAmC,EAAE,QAAQ,CAAC,CAAC,GAAG;YAE/F,4FAA4F;YAC5F,+EAA+E;YAC/E,2EAA2E;YAC3E,+EAA+E;YAC/E,yBAAyB;YAEzB,MAAM,SAAS,MAAM,MAAM,eAAe,CAAC;YAC3C,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,QAAQ,OAAO,QAAQ,CAAC,IAAI,GAAG,IAAI;YAAG;QACrE;QAEA,IAAI,SAAS,QAAQ;YACjB,MAAM,SAAS,CAAC;;;;;YAKhB,EAAE,SAAS;YAEX,MAAM,SAAS,MAAM,MAAM,eAAe,CAAC;YAC3C,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,QAAQ,OAAO,QAAQ,CAAC,IAAI,GAAG,IAAI;YAAG;QACrE;QAEA,IAAI,SAAS,gBAAgB;YACzB,MAAM,SAAS,CAAC;;;;;;;;;;;YAWhB,EAAE,SAAS;YAEX,MAAM,SAAS,MAAM,MAAM,eAAe,CAAC;YAC3C,MAAM,OAAO,OAAO,QAAQ,CAAC,IAAI;YACjC,MAAM,YAAY,KAAK,KAAK,CAAC;YAC7B,IAAI,WAAW;gBACX,OAAO,gJAAY,CAAC,IAAI,CAAC,KAAK,KAAK,CAAC,SAAS,CAAC,EAAE;YACpD;YACA,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAuB,GAAG;gBAAE,QAAQ;YAAI;QAC9E;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE,OAAO;QAAe,GAAG;YAAE,QAAQ;QAAI;IACtE,EAAE,OAAO,OAAY;QACjB,QAAQ,KAAK,CAAC,wBAAwB;QACtC,OAAO,gJAAY,CAAC,IAAI,CAAC;YACrB,OAAO;YACP,SAAS,MAAM,OAAO,IAAI,OAAO;QACrC,GAAG;YAAE,QAAQ;QAAI;IACrB;AACJ"}}]
}